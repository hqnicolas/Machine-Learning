# TRABALHO FINAL DE MACHINE LEARNING

## 1. CONTEXTO GERAL

O aprendizado de máquina (Machine Learning) é uma das áreas centrais da Inteligência Artificial moderna, presente em sistemas de recomendação, diagnóstico médico, previsão de demanda, manutenção preditiva e análise de comportamento.

Este trabalho tem como objetivo permitir que os alunos vivenciem todas as etapas de um projeto real de Machine Learning, aplicando na prática os conceitos teóricos estudados ao longo da disciplina.

O projeto será desenvolvido em grupo (3 até 5 pessoas), promovendo colaboração, pensamento crítico e habilidades práticas de análise e implementação de modelos inteligentes.

## 2. OBJETIVO GERAL

Desenvolver um projeto completo de Machine Learning que resolva um problema real utilizando um dataset, demonstrando:

* Capacidade de formular e estruturar um problema baseado em dados;
* Domínio das etapas de pré-processamento, análise exploratória e modelagem;
* Aplicação prática de técnicas de avaliação e deploy do modelo treinado.

## 3. TEMA E LIBERDADE DE ESCOLHA

Cada grupo deverá:

* Escolher um tema livre, relacionado a qualquer área de interesse (ex.: saúde, educação, finanças, esportes, energia, meio ambiente, indústria etc.);
* Utilizar um dataset público proveniente de fontes como Kaggle, UCI ML Repository, Google Dataset Search ou dados.gov.br;
* Formular uma pergunta de pesquisa clara, que possa ser respondida por técnicas de aprendizado supervisionado ou não supervisionado.

## 4. ETAPAS DO TRABALHO E PONTUAÇÃO

| Etapa | Descrição | Pontos |
| --- | --- | --- |
| 1. Escolha do Tema e Dataset | Definir um problema real, justificar a relevância e apresentar a fonte do dataset. | 1,0 |
| 2. Formulação do Problema | Descrever o objetivo do projeto e o tipo de aprendizado (classificação, regressão, agrupamento, etc.). | 1,0 |
| 3. Preparação dos Dados | Realizar limpeza, tratamento de nulos e outliers, normalização/padronização e codificação. Justificar todas as decisões. | 1,5 |
| 4. Análise Exploratória (EDA) | Explorar o conjunto de dados com estatísticas e gráficos, identificando padrões e correlações. | 1,5 |
| 5. Modelagem e Avaliação | Aplicar pelo menos dois algoritmos diferentes e utilizar métricas adequadas. O uso de GridSearchCV ou técnicas equivalentes é recomendado. | 2,0 |
| 6. Deploy do Modelo | Disponibilizar o modelo treinado via aplicação web (Streamlit, Gradio) ou API (Flask, FastAPI) com interface. | 2,0 |
| 7. Conclusão e Discussão | Interpretar os resultados, discutir limitações e propor melhorias. | 1,0 |

**Total: 10,0 pontos**

## 5. APRESENTAÇÃO OBRIGATÓRIA

A apresentação oral é obrigatória para validação do trabalho. Cada grupo deverá apresentar o projeto (10 a 15 minutos), explicando todas as etapas e demonstrando domínio do conteúdo.

> A ausência de apresentação implica nota zero em todas as etapas, independentemente do relatório ou notebook entregues.

## 6. ENTREGÁVEIS

1.  Notebook Jupyter (.ipynb) com o código completo, comentários e resultados;
2.  Apresentação (slides) de 10 a 15 minutos, com participação de todos os integrantes.

## 7. FERRAMENTAS RECOMENDADAS

* **Python**: pandas, numpy, matplotlib, seaborn, scikit-learn, xgboost;
* **Otimização**: GridSearchCV, Randomized SearchCV, Optuna ou similar;
* **Ambientes**: Google Colab ou Jupyter Notebook;
* **Visualização**: seaborn, plotly, matplotlib;
* **Deploy**: Streamlit, Gradio, FastAPI, Flask, Render, Hugging Face Spaces;
* **Fontes de dados**: Kaggle, UCI ML Repository, Google Dataset Search, dados.gov.br.

## 8. CRITÉRIOS COMPLEMENTARES

* Organização e clareza do código;
* Coerência entre problema e método escolhido;
* Participação equilibrada entre os integrantes;
* **Apresentação obrigatória**: ausência implica nota zero em todas as etapas.
