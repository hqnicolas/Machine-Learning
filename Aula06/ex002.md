2.  **Assista ao vídeo: [O viés humano e a ética por trás da Inteligência Artificial | Ana Cristina | TEDxNiteroi](https://www.youtube.com/watch?v=1sS1A3p8a3Q). Responda às questões:**
    * O que é viés em Inteligência Artificial? Explique com suas próprias palavras.
    * O vídeo mostra que o viés em IA pode ter diferentes origens. Cite dois exemplos de onde esse viés pode surgir.
    * Como o viés humano pode ser “transferido” para um algoritmo de IA?
    * A palestrante menciona possíveis impactos negativos de decisões automatizadas. Cite um exemplo apresentado no vídeo e explique por que ele é preocupante.
    * Em sua opinião, quem deve ser responsável por garantir que a IA seja ética: os programadores, as empresas, o governo ou a sociedade? Justifique.

-----

#### O que é viés em Inteligência Artificial? Explique com suas próprias palavras.

Viés em IA é a tendência de um algoritmo tomar decisões sistematicamente injustas ou imprecisas para certos grupos de pessoas. Isso acontece porque o modelo aprendeu padrões "errados" ou incompletos a partir dos dados, refletindo preconceitos existentes no mundo real ou falhas no processo de coleta e treinamento. Em vez de ser neutro, o algoritmo acaba perpetuando e até amplificando desigualdades.

#### O vídeo mostra que o viés em IA pode ter diferentes origens. Cite dois exemplos de onde esse viés pode surgir.

1.  **Dados de Treinamento Desbalanceados ou Preconceituosos:** O viés pode surgir quando os dados usados para treinar o modelo refletem preconceitos históricos da sociedade. Por exemplo, se um algoritmo de recrutamento é treinado com dados de contratações passadas de uma empresa que historicamente contratou mais homens para cargos de liderança, ele aprenderá a favorecer candidatos do sexo masculino.
2.  **Viés na Seleção de Features (Variáveis):** A escolha das variáveis que alimentam o modelo pode introduzir viés. Um exemplo seria usar o CEP como variável em um modelo de análise de crédito. Como o CEP está fortemente correlacionado com a renda e a etnia em muitas cidades, o uso dessa variável pode levar a decisões discriminatórias contra moradores de bairros de baixa renda ou de minorias.

#### Como o viés humano pode ser “transferido” para um algoritmo de IA?

O viés humano é transferido para um algoritmo de IA principalmente através dos **dados**. Os algoritmos aprendem padrões a partir dos dados que lhes são fornecidos. Se esses dados foram gerados por decisões humanas enviesadas (como no exemplo de contratações), a IA aprenderá e replicará esses mesmos vieses. Além disso, os próprios desenvolvedores podem, de forma não intencional, introduzir seus vieses ao selecionar quais dados coletar, quais variáveis considerar importantes e como interpretar os resultados do modelo.

#### A palestrante menciona possíveis impactos negativos de decisões automatizadas. Cite um exemplo apresentado no vídeo e explique por que ele é preocupante.

Um exemplo citado é o de sistemas de reconhecimento facial que apresentam taxas de erro significativamente maiores para mulheres e pessoas de pele escura. Isso é preocupante porque, se essa tecnologia for usada por forças policiais para identificar suspeitos, pode levar à prisão injusta de pessoas inocentes pertencentes a esses grupos. A decisão automatizada, tida como "objetiva", acaba reforçando a discriminação e causando danos reais e graves na vida das pessoas.

#### Em sua opinião, quem deve ser responsável por garantir que a IA seja ética?

  * A responsabilidade por garantir uma IA ética deve ser **compartilhada**.
      * **Programadores e Cientistas de Dados:** Têm a responsabilidade técnica de auditar os dados em busca de vieses, escolher algoritmos justos e testar os modelos para identificar impactos desiguais.
      * **Empresas:** Devem criar uma cultura de ética em IA, investir em diversidade em suas equipes, definir diretrizes claras e ser transparentes sobre como seus sistemas funcionam e tomam decisões.
      * **Governo:** Precisa criar regulações e leis que estabeleçam limites, garantam a fiscalização e protejam os cidadãos de danos causados por sistemas de IA, exigindo auditorias e responsabilidade.
      * **Sociedade:** Deve estar ciente dos riscos, cobrar transparência e participar do debate público, garantindo que a tecnologia seja desenvolvida para o bem comum.
        A responsabilidade não pode recair sobre um único grupo, pois o problema é complexo e multifacetado.

