-----

11. **O que diferencia os critérios de divisão como o Índice de Gini e a Entropia/Ganho de Informação? Em que cenários um poderia ser preferível ao outro na construção de uma árvore?**

O **Índice de Gini** e a **Entropia/Ganho de Informação** são critérios usados para medir a "pureza" de um nó em uma árvore de decisão. O objetivo é fazer a divisão que resulte nos nós filhos mais puros possíveis.

  * **Índice de Gini:** Mede a probabilidade de um elemento aleatoriamente escolhido no nó ser classificado incorretamente. Varia de 0 (nó completamente puro) a 0.5 (impureza máxima, com distribuição 50/50 das classes).
  * **Entropia:** Mede o grau de desordem ou incerteza em um nó. Varia de 0 (nó puro) a 1 (impureza máxima). O **Ganho de Informação** é a redução na entropia após uma divisão.

**Diferenças e Cenários de Uso:**

  * **Computacionalmente:** O cálculo do Índice de Gini é ligeiramente mais rápido, pois não envolve um cálculo de logaritmo como a Entropia. Por isso, é o padrão em bibliotecas como o Scikit-learn.
  * **Resultado Prático:** Na maioria dos casos, ambos os critérios levam a árvores muito semelhantes e a performance final é praticamente a mesma.
  * **Sensibilidade:** A Entropia tende a criar árvores um pouco mais balanceadas, enquanto o Gini pode ser mais propenso a isolar a classe majoritária em um dos lados da divisão. No entanto, essa diferença raramente é significativa na prática.

