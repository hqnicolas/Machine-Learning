-----

9.  **Por que o SVM tenta encontrar a maior margem possível entre as classes? O que o SVM faz quando os dados não podem ser separados por uma linha reta?**

O SVM (Support Vector Machine) tenta encontrar a **maior margem possível** entre as classes porque uma margem maior implica em um classificador mais robusto e com melhor capacidade de generalização. A ideia é que o hiperplano que está mais distante dos pontos de dados mais próximos de cada classe (os "vetores de suporte") será menos sensível a pequenas variações nos dados e, portanto, mais provável de classificar corretamente novos exemplos.

Quando os dados **não podem ser separados por uma linha reta** (ou um hiperplano), o SVM utiliza duas técnicas principais:

1.  **Margens Suaves (Soft Margin):** Permite que alguns pontos de dados violem a margem ou até mesmo sejam classificados incorretamente. Um hiperparâmetro `C` controla a penalidade para essas violações, permitindo um equilíbrio entre maximizar a margem e minimizar os erros de classificação.
2.  **Truque do Kernel (Kernel Trick):** Mapeia os dados para um espaço de dimensão maior, onde eles possam ser linearmente separáveis. Por exemplo, dados que não são separáveis em 2D podem se tornar separáveis por um plano em 3D. Kernels comuns incluem o Polinomial, o RBF (Radial Basis Function) e o Sigmoid.

